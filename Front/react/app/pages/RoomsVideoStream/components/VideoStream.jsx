import { use, useRef, useEffect, useState } from "react"
import { useParams } from "react-router-dom"
import { UserContext } from "../../../data/context.js"
import rememberPage from "../../../modules/rememberPage.js"
import MainComponents from "../../components/MainComponents/MainComponents.jsx"
import { getWebSocketDjango } from "../../../modules/getWebSocket.js"
import { qualitySettings } from "../../../data/qualitySettings.js"

export default function VideoStream() {
    var { user } = use(UserContext)
    var [currentSpeaker, setCurrentSpeaker] = useState(null)
    var [isSpeaking, setIsSpeaking] = useState(false)

    var params = useParams()
    var videoRef = useRef(null)
    var canvasRef = useRef(null)
    var canvasModalRef = useRef(null)
    var [isFullscreen, setIsFullscreen] = useState(false)
    var webSocketVideo = useRef(null)
    var webSocketAudio = useRef(null)
    var [isStreaming, setIsStreaming] = useState(false)
    var [isScreenSharing, setIsScreenSharing] = useState(false)
    var [error, setError] = useState("")
    var [activeUsers, setActiveUsers] = useState([])
    var streamRef = useRef(null)
    var animationRef = useRef(null)

    var [isAudioStreaming, setIsAudioStreaming] = useState(false)
    var [audioLevel, setAudioLevel] = useState(0)
    var audioContextRef = useRef(null)
    var audioStreamRef = useRef(null)
    var audioProcessorRef = useRef(null)
    var screenStreamRef = useRef(null)
    var [screenQuality, setScreenQuality] = useState("720p")
    var [compressionQuality, setCompressionQuality] = useState(0.9)

    var [currentFPS, setCurrentFPS] = useState(10)

    rememberPage(`video_stream/${params.username}/${params.room_id}`)

    // –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–º–µ—Å—Ç–æ –º–æ–¥—É–ª–µ–π
    var checkCameraAccess = async () => {
        try {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                setError("–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ.")
                return false
            }
            return true
        } catch (err) {
            console.error("Camera access error:", err)
            setError("–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–º–µ—Ä–µ")
            return false
        }
    }

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
    var startScreenSharing = async () => {
        try {
            setError("")
            console.log("Starting screen sharing...")

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É API –∑–∞—Ö–≤–∞—Ç–∞ —ç–∫—Ä–∞–Ω–∞
            if (!navigator.mediaDevices || !navigator.mediaDevices.getDisplayMedia) {
                setError("–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞—Ö–≤–∞—Ç —ç–∫—Ä–∞–Ω–∞")
                return false
            }

            var quality = qualitySettings[screenQuality]

            // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –∑–∞—Ö–≤–∞—Ç —ç–∫—Ä–∞–Ω–∞
            var screenStream = await navigator.mediaDevices.getDisplayMedia({
                video: {
                    cursor: "always",
                    displaySurface: "monitor", // –∏–ª–∏ "browser", "window", "monitor"
                    logicalSurface: false,
                    width: { ideal: quality.width, max: quality.width },
                    height: { ideal: quality.height, max: quality.height },
                    frameRate: { ideal: quality.frameRate, max: 60 },
                    aspectRatio: { ideal: 16 / 9 },
                    resizeMode: "crop-and-scale",
                },
                audio: false,
            })

            screenStreamRef.current = screenStream

            // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞—Ö–≤–∞—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
            screenStream.getVideoTracks()[0].onended = () => {
                console.log("Screen sharing stopped by user")
                stopScreenSharing()
            }

            // –ó–∞–º–µ–Ω—è–µ–º –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫ –∫–∞–º–µ—Ä—ã –Ω–∞ –ø–æ—Ç–æ–∫ —ç–∫—Ä–∞–Ω–∞
            if (videoRef.current) {
                videoRef.current.srcObject = screenStream
            }

            // –û–±–Ω–æ–≤–ª—è–µ–º streamRef –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ captureAndSendFrames
            streamRef.current = screenStream

            console.log("Screen sharing started successfully")
            return true

        } catch (error) {
            console.error("Error starting screen sharing:", error)
            var errorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—é —ç–∫—Ä–∞–Ω–∞. "

            if (error.name === "NotAllowedError") {
                errorMessage += "–î–æ—Å—Ç—É–ø –∫ —ç–∫—Ä–∞–Ω—É –∑–∞–ø—Ä–µ—â–µ–Ω."
            } else if (error.name === "NotFoundError") {
                errorMessage += "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏."
            } else {
                errorMessage += error.message
            }

            setError(errorMessage)
            return false
        }
    }

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
    var stopScreenSharing = async () => {
        console.log("Stopping screen sharing...")

        if (screenStreamRef.current) {
            screenStreamRef.current.getTracks().forEach(track => track.stop())
            screenStreamRef.current = null
        }

        // –ï—Å–ª–∏ –±—ã–ª–∞ –∞–∫—Ç–∏–≤–Ω–∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ –∫–∞–º–µ—Ä—É
        if (isStreaming && !isScreenSharing) {
            await startStreamingVideo()
        } else if (videoRef.current) {
            videoRef.current.srcObject = null
        }

        setIsScreenSharing(false)
    }

    // –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –Ω–∞—á–∞–ª–∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏ –≤–∏–¥–µ–æ
    var startStreamingVideo = async () => {
        try {
            setError("")

            // –ï—Å–ª–∏ –∞–∫—Ç–∏–≤–Ω–∞ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —ç–∫—Ä–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–µ
            if (isScreenSharing && screenStreamRef.current) {
                streamRef.current = screenStreamRef.current
                if (videoRef.current) {
                    videoRef.current.srcObject = screenStreamRef.current
                }
                return
            }

            var hasAccess = await checkCameraAccess()
            if (!hasAccess) {
                return
            }

            var quality = qualitySettings[screenQuality]

            var constraints = {
                video: {
                    width: { ideal: quality.width, max: quality.width },
                    height: { ideal: quality.height, max: quality.height },
                    frameRate: { ideal: quality.frameRate, max: 60 },
                    facingMode: "user",
                    aspectRatio: { ideal: 16 / 9 },
                    resizeMode: "crop-and-scale",
                },
                audio: false,
            }

            if (navigator.mediaDevices.getSupportedConstraints().frameRate) {
                constraints.video.frameRate = { ideal: quality.frameRate, max: 60 }
            }

            var stream = await navigator.mediaDevices.getUserMedia(constraints)
            streamRef.current = stream

            if (videoRef.current) {
                videoRef.current.srcObject = stream
                videoRef.current.onloadedmetadata = () => {
                    console.log("Video metadata loaded, dimensions:",
                        videoRef.current.videoWidth, "x", videoRef.current.videoHeight)
                }
            }

            if (stream.getVideoTracks().length > 0) {
                var track = stream.getVideoTracks()[0]
                var capabilities = track.getCapabilities ? track.getCapabilities() : {}
                var settings = track.getSettings ? track.getSettings() : {}

                console.log("Camera capabilities:", capabilities)
                console.log("Current camera settings:", settings)

                if (capabilities.zoom) {
                    try {
                        await track.applyConstraints({
                            advanced: [{ zoom: capabilities.zoom.min }]
                        })
                    } catch (constraintError) {
                        console.log("Cannot apply zoom constraints:", constraintError)
                    }
                }
            }
        } catch (error) {
            console.error("Error accessing camera:", error)
            var errorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ. "
            if (error.name === "NotAllowedError") {
                errorMessage += "–î–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ –∑–∞–ø—Ä–µ—â–µ–Ω."
            } else if (error.name === "NotFoundError") {
                errorMessage += "–ö–∞–º–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."
            } else if (error.name === "OverconstrainedError") {
                errorMessage += "–¢—Ä–µ–±—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞–º–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."
                try {
                    var basicStream = await navigator.mediaDevices.getUserMedia({
                        video: true,
                        audio: false
                    })
                    streamRef.current = basicStream
                    if (videoRef.current) {
                        videoRef.current.srcObject = basicStream
                    }
                    setError("")
                    return
                } catch (basicError) {
                    console.error("Basic camera access also failed:", basicError)
                }
            } else {
                errorMessage += error.message
            }
            setError(errorMessage)
        }
    }

    var stopStreamingVideo = async () => {
        console.log("Stopping video streaming...")

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—è —ç–∫—Ä–∞–Ω–∞
        if (!isScreenSharing) {
            if (streamRef.current) {
                streamRef.current.getTracks().forEach(track => {
                    track.stop()
                })
                streamRef.current = null
            }

            if (animationRef.current) {
                cancelAnimationFrame(animationRef.current)
                animationRef.current = null
            }

            if (videoRef.current) {
                videoRef.current.srcObject = null
            }
        }
        setCurrentSpeaker(null)
    }

    var startStreamingAudio = async () => {
        try {
            setError("")
            console.log("Starting audio streaming...")

            var hasAccess = await checkCameraAccess()
            if (!hasAccess) {
                return
            }

            // –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            var audioConstraints = {
                echoCancellation: { ideal: true },
                noiseSuppression: { ideal: true },
                autoGainControl: { ideal: true },
                // –£–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
                sampleRate: { ideal: 48000, min: 44100 }, // CD –∫–∞—á–µ—Å—Ç–≤–æ
                channelCount: { ideal: 1, max: 2 }, // –º–æ–Ω–æ –∏–ª–∏ —Å—Ç–µ—Ä–µ–æ
                sampleSize: { ideal: 16 }, // –±–∏—Ç–Ω–æ—Å—Ç—å
                // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è Mac
                googEchoCancellation: true,
                googAutoGainControl: true,
                googNoiseSuppression: true,
                googHighpassFilter: true,
                // –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è)
                latency: { ideal: 0.01 },
                volume: { ideal: 1.0 }
            }

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
            var supportedConstraints = navigator.mediaDevices.getSupportedConstraints()
            console.log("Supported audio constraints:", supportedConstraints)

            // –£–±–∏—Ä–∞–µ–º –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            var finalConstraints = {}
            Object.keys(audioConstraints).forEach(key => {
                if (supportedConstraints[key]) {
                    finalConstraints[key] = audioConstraints[key]
                }
            })

            // –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –±—Ä–∞—É–∑–µ—Ä–æ–≤
            var stream = await navigator.mediaDevices.getUserMedia({
                video: false,
                audio: finalConstraints
            }).catch(async (error) => {
                console.log("High quality audio failed, trying basic settings:", error)

                // –†–µ–∑–µ—Ä–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                return await navigator.mediaDevices.getUserMedia({
                    video: false,
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 44100,
                        channelCount: 1
                    }
                })
            })

            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            var audioTrack = stream.getAudioTracks()[0]
            if (audioTrack && audioTrack.getSettings) {
                var actualSettings = audioTrack.getSettings()
                console.log("Actual audio settings:", actualSettings)

                // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
                var capabilities = audioTrack.getCapabilities ? audioTrack.getCapabilities() : {}
                console.log("Audio capabilities:", capabilities)
            }

            audioStreamRef.current = stream
            await startAudioProcessing(stream)

            console.log("High quality audio streaming started")

        } catch (error) {
            console.error("Error accessing microphone:", error)
            var errorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. "
            if (error.name === "NotAllowedError") {
                errorMessage += "–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â–µ–Ω."
            } else if (error.name === "NotFoundError") {
                errorMessage += "–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω."
            } else if (error.name === "OverconstrainedError") {
                errorMessage += "–¢—Ä–µ–±—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
                // –ü—Ä–æ–±—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                try {
                    var basicStream = await navigator.mediaDevices.getUserMedia({
                        video: false,
                        audio: true // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                    })
                    audioStreamRef.current = basicStream
                    await startAudioProcessing(basicStream)
                    setError("") // –û—á–∏—â–∞–µ–º –æ—à–∏–±–∫—É
                    return
                } catch (basicError) {
                    console.error("Basic microphone access also failed:", basicError)
                }
            } else {
                errorMessage += error.message
            }
            setError(errorMessage)
            setIsAudioStreaming(false)
        }
    }

    var stopStreamingAudio = async () => {
        console.log("Stopping audio streaming...")

        // –û—á–∏—â–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏
        if (audioContextRef.current && audioContextRef.current._checkInterval) {
            clearInterval(audioContextRef.current._checkInterval)
        }

        if (audioProcessorRef.current) {
            audioProcessorRef.current.disconnect()
            audioProcessorRef.current = null
        }

        if (audioContextRef.current) {
            try {
                await audioContextRef.current.close()
            } catch (error) {
                console.error("Error closing audio context:", error)
            }
            audioContextRef.current = null
        }

        if (audioStreamRef.current) {
            audioStreamRef.current.getTracks().forEach(track => track.stop())
            audioStreamRef.current = null
        }

        setIsSpeaking(false)
        setCurrentSpeaker(null)
        setAudioLevel(0)
    }

    var encodeAudio = (audioData) => {
        try {
            var array = new Uint8Array(audioData.length)
            for (var i = 0; i < audioData.length; i++) {
                var sample = Math.max(-1, Math.min(1, audioData[i]))
                array[i] = Math.floor((sample + 1) * 127)
            }
            var binaryString = String.fromCharCode.apply(null, array)
            return btoa(binaryString)
        } catch (error) {
            console.error("Error encoding audio:", error)
            return ""
        }
    }

    var decodeAudio = (base64Data) => {
        try {
            var binaryString = atob(base64Data)
            var array = new Uint8Array(binaryString.length)
            for (let i = 0; i < binaryString.length; i++) {
                array[i] = binaryString.charCodeAt(i)
            }
            var floatBuffer = new Float32Array(array.length)
            for (let i = 0; i < array.length; i++) {
                floatBuffer[i] = (array[i] / 127) - 1
            }
            return floatBuffer
        } catch (error) {
            console.error("Error decoding audio:", error)
            return new Float32Array(0)
        }
    }

    var playReceivedAudio = async (audioData) => {
        try {
            var audioContext = new (window.AudioContext || window.webkitAudioContext)()
            var decodedData = decodeAudio(audioData)
            var buffer = audioContext.createBuffer(1, decodedData.length, audioContext.sampleRate)
            buffer.copyToChannel(decodedData, 0)
            var source = audioContext.createBufferSource()
            source.buffer = buffer
            source.connect(audioContext.destination)
            source.start()
        } catch (error) {
            console.error("Error playing audio:", error)
        }
    }

    var displayProcessedFrame = async (frameData) => {
        var img = new Image()
        img.onload = async () => {
            var mainContext, modalContext

            if (canvasRef.current) {
                mainContext = await canvasRef.current.getContext("2d", {
                    alpha: false,
                    desynchronized: true
                })

                // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
                var displayWidth = img.naturalWidth
                var displayHeight = img.naturalHeight

                // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã canvas —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
                if (canvasRef.current.width !== displayWidth || canvasRef.current.height !== displayHeight) {
                    canvasRef.current.width = displayWidth
                    canvasRef.current.height = displayHeight
                }

                // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞
                mainContext.imageSmoothingEnabled = true
                mainContext.imageSmoothingQuality = "high"

                // –û—á–∏—â–∞–µ–º –∏ —Ä–∏—Å—É–µ–º –±–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
                await mainContext.clearRect(0, 0, displayWidth, displayHeight)
                await mainContext.drawImage(
                    img,
                    0, 0,
                    displayWidth,
                    displayHeight
                )
            }

            if (canvasModalRef.current) {
                modalContext = await canvasModalRef.current.getContext("2d", {
                    alpha: false,
                    desynchronized: true
                })

                // –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –ø–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
                var containerWidth = window.innerWidth
                var containerHeight = window.innerHeight

                // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã canvas —Ä–∞–≤–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º –æ–∫–Ω–∞
                if (canvasModalRef.current.width !== containerWidth || canvasModalRef.current.height !== containerHeight) {
                    canvasModalRef.current.width = containerWidth
                    canvasModalRef.current.height = containerHeight
                }

                // –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–∞—Å—à—Ç–∞–± —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
                var scale = Math.min(
                    containerWidth / img.naturalWidth,
                    containerHeight / img.naturalHeight
                )

                var renderWidth = img.naturalWidth * scale
                var renderHeight = img.naturalHeight * scale
                var offsetX = (containerWidth - renderWidth) / 2
                var offsetY = (containerHeight - renderHeight) / 2

                // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞
                modalContext.imageSmoothingEnabled = true
                modalContext.imageSmoothingQuality = "high"

                // –û—á–∏—â–∞–µ–º –≤–µ—Å—å canvas
                await modalContext.clearRect(0, 0, containerWidth, containerHeight)

                // –†–∏—Å—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏
                await modalContext.drawImage(
                    img,
                    0, 0,
                    img.naturalWidth,
                    img.naturalHeight,
                    offsetX,
                    offsetY,
                    renderWidth,
                    renderHeight
                )
            }
        }
        img.onerror = () => {
            console.error("Error loading broadcast image")
        }

        img.src = frameData

        // –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img.decode && img.decode().catch(() => {
            console.log("Image decode failed, falling back to onload")
        })
    }

    var restartAudioContext = async () => {
        try {
            console.log("Restarting AudioContext...")

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            if (audioProcessorRef.current) {
                audioProcessorRef.current.disconnect()
                audioProcessorRef.current = null
            }

            if (audioContextRef.current) {
                await audioContextRef.current.close()
            }

            // –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π AudioContext
            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()

            // –ñ–¥–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            if (audioContextRef.current.state === "suspended") {
                await audioContextRef.current.resume()
            }

            console.log("AudioContext restarted successfully")
            return true
        } catch (error) {
            console.error("Error restarting AudioContext:", error)
            return false
        }
    }

    var startAudioProcessing = async (stream) => {
        try {
            console.log("Starting audio processing...")

            // –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º AudioContext
            var success = await restartAudioContext()
            if (!success) {
                throw new Error("Failed to initialize AudioContext")
            }

            var source = audioContextRef.current.createMediaStreamSource(stream)
            audioProcessorRef.current = audioContextRef.current.createScriptProcessor(16384, 1, 1)

            var errorCount = 0
            var MAX_ERRORS = 3

            audioProcessorRef.current.onaudioprocess = (event) => {
                if (!isAudioStreaming || !webSocketAudio.current || webSocketAudio.current.readyState !== WebSocket.OPEN) {
                    return
                }

                try {
                    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ AudioContext
                    if (audioContextRef.current.state !== "running") {
                        console.log("AudioContext not running, state:", audioContextRef.current.state)
                        if (errorCount < MAX_ERRORS) {
                            errorCount++
                            audioContextRef.current.resume().catch(console.error)
                        }
                        return
                    }

                    var audioData = event.inputBuffer.getChannelData(0)
                    var sum = 0
                    for (var i = 0; i < audioData.length; i++) {
                        sum += Math.abs(audioData[i])
                    }
                    var level = sum / audioData.length
                    setAudioLevel(level)

                    if (level > 0.01) {
                        setIsSpeaking(true)
                        var encoded = encodeAudio(audioData)
                        if (encoded && webSocketAudio.current.readyState === WebSocket.OPEN) {
                            webSocketAudio.current.send(JSON.stringify({
                                type: "audio_data",
                                audio: encoded,
                                room: params.room_id,
                                user: user,
                                active_users: activeUsers,
                                is_speaking: true,
                                current_speaker: user,
                                timestamp: Date.now(),
                            }))
                        }
                        errorCount = 0 // —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ
                    } else {
                        setIsSpeaking(false)
                    }
                } catch (error) {
                    console.error("Error in audio processing:", error)
                    errorCount++
                    setIsSpeaking(false)

                    // –ï—Å–ª–∏ –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥, –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º AudioContext
                    if (errorCount >= MAX_ERRORS) {
                        console.log("Too many errors, restarting AudioContext...")
                        setTimeout(() => {
                            if (isAudioStreaming && audioStreamRef.current) {
                                restartAudioContext().then(success => {
                                    if (success && audioStreamRef.current) {
                                        var source = audioContextRef.current.createMediaStreamSource(audioStreamRef.current)
                                        source.connect(audioProcessorRef.current)
                                    }
                                })
                            }
                        }, 100)
                    }
                }
            }

            source.connect(audioProcessorRef.current)
            audioProcessorRef.current.connect(audioContextRef.current.destination)
            console.log("Audio processing started successfully")

        } catch (error) {
            console.error("Error starting audio processing:", error)
            setError("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ: " + error.message)
            setIsSpeaking(false)
            setIsAudioStreaming(false)
        }
    }

    var captureAndSendFrames = async () => {
        if (!isStreaming || !webSocketVideo.current || webSocketVideo.current.readyState !== WebSocket.OPEN) {
            animationRef.current = null
            return
        }

        var video = videoRef.current
        var canvas = canvasRef.current

        if (!video || !canvas || video.videoWidth === 0 || video.videoHeight === 0) {
            animationRef.current = requestAnimationFrame(captureAndSendFrames)
            return
        }

        try {
            var context, frameData

            context = await canvas.getContext("2d", {
                alpha: false, // –û—Ç–∫–ª—é—á–∞–µ–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                desynchronized: true // –í–∫–ª—é—á–∞–µ–º –¥–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            })

            canvas.width = video.videoWidth
            canvas.height = video.videoHeight

            // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
            context.imageSmoothingEnabled = true
            context.imageSmoothingQuality = "high"

            // –û—á–∏—â–∞–µ–º canvas –ø–µ—Ä–µ–¥ –æ—Ç—Ä–∏—Å–æ–≤–∫–æ–π
            await context.clearRect(0, 0, canvas.width, canvas.height)

            // –†–∏—Å—É–µ–º –≤–∏–¥–µ–æ —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            await context.drawImage(
                video,
                0, 0,
                canvas.width,
                canvas.height,
            )

            // –ò—Å–ø–æ–ª—å–∑—É–µ–º WebP –µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–∂–∞—Ç–∏—è
            var format = "image/jpeg"
            if (canvas.toDataURL("image/webp", compressionQuality).length > 0) {
                format = "image/webp"
            }

            frameData = await canvas.toDataURL(format, compressionQuality)

            if (webSocketVideo.current.readyState === WebSocket.OPEN) {
                var data = JSON.stringify({
                    type: "video_frame",
                    frame: frameData,
                    room: params.room_id,
                    user: user,
                    active_users: activeUsers,
                    is_speaking: isSpeaking,
                    current_speaker: currentSpeaker,
                    timestamp: Date.now(),
                })
                await webSocketVideo.current.send(data)
            }
        } catch (err) {
            console.error("Error sending frame:", err)
        }

        var frameInterval = 1000 / currentFPS
        setTimeout(() => {
            animationRef.current = requestAnimationFrame(captureAndSendFrames)
        }, frameInterval)
    }

    // –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏ —ç–∫—Ä–∞–Ω–∞
    var toggleScreenSharing = async () => {
        if (isScreenSharing) {
            await stopScreenSharing()
        } else {
            var success = await startScreenSharing()
            if (success) {
                setIsScreenSharing(true)
                // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ–º —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—é –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ –≤—ã–∫–ª—é—á–µ–Ω–∞
                if (!isStreaming) {
                    setIsStreaming(true)
                }
            }
        }
    }

    var connectStreamWebSocket = async () => {
        try {
            console.log("Connecting WebSocket...")

            webSocketVideo.current = getWebSocketDjango({
                socket_name: "videoStreamSocket",
                path: `video_stream/${params.room_id}/${user.id}/`,
            })
            webSocketAudio.current = getWebSocketDjango({
                socket_name: "audioStreamSocket",
                path: `audio_stream/${params.room_id}/${user.id}/`,
            })

            webSocketVideo.current.onmessage = async (event) => {
                try {
                    var data

                    // Check if data is Blob (binary data)
                    if (event.data instanceof Blob) {
                        // Convert Blob to text
                        const text = await event.data.text()
                        data = JSON.parse(text)
                    } else {
                        // Data is already text
                        data = JSON.parse(event.data)
                    }

                    var delay = Number(Date.now() - data.timestamp)
                    if (delay < 1000) {
                        await displayProcessedFrame(data.frame)
                        setActiveUsers(prev => {
                            var users = new Set(prev)
                            if (data.user && data.user.username) {
                                users.add(data.user.username)
                            }
                            users.add(user.username)
                            return Array.from(users)
                        })
                    }
                    if (data.type === "error") {
                        setError(`Server error: ${data.message}`)
                    }
                } catch (err) {
                    console.error("Error parsing video message:", err)
                }
            }

            webSocketAudio.current.onmessage = async (event) => {
                try {
                    var data

                    // Check if data is Blob (binary data)
                    if (event.data instanceof Blob) {
                        // Convert Blob to text
                        const text = await event.data.text()
                        data = JSON.parse(text)
                    } else {
                        // Data is already text
                        data = JSON.parse(event.data)
                    }

                    if (data.user.username !== user.username) {
                        var delay = Number(Date.now() - data.timestamp)
                        if (delay < 1000) {
                            await playReceivedAudio(data.audio)
                            setActiveUsers(prev => {
                                var users = new Set(prev)
                                if (data.user && data.user.username) {
                                    users.add(data.user.username)
                                }
                                users.add(user.username)
                                return Array.from(users)
                            })
                            setCurrentSpeaker(data.user)
                        }
                    }
                } catch (err) {
                    console.error("Error parsing audio message:", err)
                }
            }

        } catch (err) {
            console.error("Error creating WebSocket:", err)
            setError("Failed to establish connection")
        }
    }

    var disconnectStreamWebSocket = async () => {
        if (webSocketVideo.current) {
            await webSocketVideo.current.close()
            webSocketVideo.current = null
        }
        if (webSocketAudio.current) {
            await webSocketAudio.current.close()
            webSocketAudio.current = null
        }
    }

    // –≠—Ñ—Ñ–µ–∫—Ç—ã
    useEffect(() => {
        checkCameraAccess()
        connectStreamWebSocket()

        return () => {
            disconnectStreamWebSocket()
            stopStreamingVideo()
            stopStreamingAudio()
            stopScreenSharing()
        }
    }, [params.room_id])

    useEffect(() => {
        if (isStreaming) {
            startStreamingVideo()
        } else {
            stopStreamingVideo()
        }
    }, [isStreaming])

    useEffect(() => {
        if (isStreaming && !animationRef.current) {
            var frameInterval = 1000 / currentFPS
            setTimeout(() => {
                animationRef.current = requestAnimationFrame(captureAndSendFrames)
            }, frameInterval)
        } else if (animationRef.current && (!isStreaming || !isSpeaking)) {
            cancelAnimationFrame(animationRef.current)
            animationRef.current = null
        }

        return () => {
            if (animationRef.current) {
                cancelAnimationFrame(animationRef.current)
                animationRef.current = null
            }
        }
    }, [isStreaming])

    useEffect(() => {
        if (isAudioStreaming) {
            startStreamingAudio()
        } else {
            stopStreamingAudio()
        }
    }, [isAudioStreaming])

    useEffect(() => {
        if (!isAudioStreaming) {
            return
        }

        var monitorInterval = setInterval(() => {
            if (audioContextRef.current && audioContextRef.current.state !== "running") {
                console.log("AudioContext state:", audioContextRef.current.state)
                audioContextRef.current.resume().catch(console.error)
            }
        }, 3000) // –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–µ - –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã

        return () => {
            clearInterval(monitorInterval)
        }
    }, [isAudioStreaming])

    return (
        <>
            <MainComponents />

            {/* Fullscreen –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ */}
            <div
                style={{
                    position: "fixed",
                    top: 0,
                    left: 0,
                    width: "100vw",
                    height: "100vh",
                    backgroundColor: "black",
                    zIndex: 9999,
                    display: isFullscreen ? "flex" : "none",
                    justifyContent: "center",
                    alignItems: "center",
                    flexDirection: "column"
                }}
            >
                {/* –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ –ø–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ */}
                <div style={{
                    position: "absolute",
                    top: "20px",
                    left: "50%",
                    transform: "translateX(-50%)",
                    display: "flex",
                    gap: "10px",
                    zIndex: 10000,
                    backgroundColor: "rgba(0, 0, 0, 0.7)",
                    padding: "10px",
                    borderRadius: "10px"
                }}>
                    <button
                        onClick={() => setIsStreaming((prev) => !prev)}
                        style={{
                            padding: "10px 20px",
                            backgroundColor: isStreaming ? "#dc3545" : "#007bff",
                            color: "white",
                            border: "none",
                            borderRadius: "5px",
                            cursor: "pointer",
                            fontSize: "14px"
                        }}
                    >
                        {isStreaming ? "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å" : "‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—é –≤–∏–¥–µ–æ"}
                    </button>

                    <button
                        onClick={toggleScreenSharing}
                        style={{
                            padding: "10px 20px",
                            backgroundColor: isScreenSharing ? "#dc3545" : "#007bff",
                            color: "white",
                            border: "none",
                            borderRadius: "5px",
                            cursor: "pointer",
                            fontSize: "14px"
                        }}
                    >
                        {isScreenSharing ? "üñ•Ô∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —ç–∫—Ä–∞–Ω" : "üñ•Ô∏è –¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è —ç–∫—Ä–∞–Ω–∞"}
                    </button>

                    <button
                        onClick={() => setIsAudioStreaming((prev) => !prev)}
                        style={{
                            padding: "10px 20px",
                            backgroundColor: isAudioStreaming ? "#dc3545" : "#007bff",
                            color: "white",
                            border: "none",
                            borderRadius: "5px",
                            cursor: "pointer",
                            fontSize: "14px"
                        }}
                    >
                        {isAudioStreaming ? "üîá –í—ã–∫–ª. –∞—É–¥–∏–æ" : "üîä –í–∫–ª. –∞—É–¥–∏–æ"}
                    </button>
                </div>

                {/* –ö–Ω–æ–ø–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è */}
                <button
                    onClick={() => setIsFullscreen(false)}
                    style={{
                        position: "absolute",
                        top: "20px",
                        right: "20px",
                        padding: "10px 20px",
                        backgroundColor: "#dc3545",
                        color: "white",
                        border: "none",
                        borderRadius: "5px",
                        cursor: "pointer",
                        zIndex: 10000
                    }}
                >
                    ‚úï –ó–∞–∫—Ä—ã—Ç—å
                </button>

                {/* Canvas –¥–ª—è –≤–∏–¥–µ–æ */}
                <canvas
                    ref={canvasModalRef}
                    style={{
                        width: "100vw",
                        height: "100vh",
                        display: "block"
                    }}
                />

                {/* –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–∫—É—â–µ–º —Å–ø–∏–∫–µ—Ä–µ –≤ –ø–æ–ª–Ω–æ—ç–∫—Ä–∞–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ */}
                {currentSpeaker && (
                    <div style={{
                        position: "absolute",
                        bottom: "20px",
                        left: "50%",
                        transform: "translateX(-50%)",
                        color: "white",
                        backgroundColor: "rgba(0, 0, 0, 0.7)",
                        padding: "10px 20px",
                        borderRadius: "5px",
                        zIndex: 10000,
                        fontSize: "16px"
                    }}>
                        {currentSpeaker.first_name} {currentSpeaker.last_name}
                    </div>
                )}
            </div>

            <div style={{ padding: "100px", textAlign: "center", maxWidth: "1200px", margin: "0 auto" }}>
                {error && (
                    <div style={{
                        padding: "15px",
                        margin: "20px 0",
                        backgroundColor: "#ffebee",
                        border: "1px solid #f44336",
                        borderRadius: "5px",
                        color: "#c62828"
                    }}>
                        {error}
                    </div>
                )}

                {/* –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ */}
                <div style={{
                    marginBottom: "20px",
                    padding: "15px",
                    borderRadius: "10px"
                }}>
                    <div style={{ display: "flex", justifyContent: "center", gap: "20px", flexWrap: "wrap" }}>
                        <div>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: <strong>{activeUsers.length}</strong></div>
                    </div>
                </div>

                {/* –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è */}
                <div style={{
                    marginBottom: "20px",
                    padding: "20px",
                    borderRadius: "10px"
                }}>
                    <div style={{ marginBottom: "15px" }}>
                        <button
                            onClick={() => setIsStreaming((prev) => !prev)}
                            style={{
                                margin: "5px",
                                padding: "12px 24px",
                                backgroundColor: isStreaming ? "#dc3545" : "#007bff",
                                color: "white",
                                border: "none",
                                borderRadius: "5px",
                                cursor: "pointer",
                                fontSize: "16px"
                            }}
                        >
                            {isStreaming ? "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å" : "‚ñ∂Ô∏è –ù–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏—é –≤–∏–¥–µ–æ"}
                        </button>

                        <button
                            onClick={toggleScreenSharing}
                            style={{
                                margin: "5px",
                                padding: "12px 24px",
                                backgroundColor: isScreenSharing ? "#dc3545" : "#007bff",
                                color: "white",
                                border: "none",
                                borderRadius: "5px",
                                cursor: "pointer",
                                fontSize: "16px"
                            }}
                        >
                            {isScreenSharing ? "üñ•Ô∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —ç–∫—Ä–∞–Ω" : "üñ•Ô∏è –¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è —ç–∫—Ä–∞–Ω–∞"}
                        </button>

                        <button
                            onClick={() => setIsAudioStreaming((prev) => !prev)}
                            style={{
                                margin: "5px",
                                padding: "12px 24px",
                                backgroundColor: isAudioStreaming ? "#dc3545" : "#007bff",
                                color: "white",
                                border: "none",
                                borderRadius: "5px",
                                cursor: "pointer",
                                fontSize: "16px"
                            }}
                        >
                            {isAudioStreaming ? "üîá –í—ã–∫–ª. –∞—É–¥–∏–æ" : "üîä –í–∫–ª. –∞—É–¥–∏–æ"}
                        </button>

                        <button
                            onClick={() => setIsFullscreen(true)}
                            style={{
                                margin: "5px",
                                padding: "12px 24px",
                                backgroundColor: "#007bff",
                                color: "white",
                                border: "none",
                                borderRadius: "5px",
                                cursor: "pointer",
                                fontSize: "16px"
                            }}
                        >
                            üì∫ –ù–∞ –≤–µ—Å—å —ç–∫—Ä–∞–Ω
                        </button>
                        <div style={{ marginTop: "10px" }}>
                            <label>FPS (–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–¥–µ–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏): {currentFPS}</label>
                            <input
                                type="range"
                                min="1"
                                max="60"
                                value={currentFPS}
                                onChange={(e) => setCurrentFPS(Number(e.target.value))}
                                style={{ marginLeft: "10px", width: "150px" }}
                            />
                        </div>
                        <div style={{ marginTop: "10px" }}>
                            <label>–ö–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å–ª–∏—Ä—É–µ–º–æ–≥–æ —ç–∫—Ä–∞–Ω–∞: </label>
                            <select
                                value={screenQuality}
                                onChange={(e) => setScreenQuality(e.target.value)}
                                style={{
                                    marginLeft: "10px",
                                    padding: "5px",
                                    borderRadius: "5px",
                                    border: "1px solid #ccc"
                                }}
                            >
                                <option value="720p">720p HD</option>
                                <option value="1080p">1080p Full HD</option>
                                <option value="2K">2K Quad HD</option>
                                <option value="4K">4K Ultra HD</option>
                            </select>
                            <div style={{ fontSize: "12px", color: "#666", marginTop: "5px" }}>
                                –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: {qualitySettings[screenQuality].width}x{qualitySettings[screenQuality].height}
                            </div>
                        </div>
                        <div style={{ marginTop: "10px" }}>
                            <label>–£—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: </label>
                            <select
                                value={compressionQuality}
                                onChange={(e) => setCompressionQuality(parseFloat(e.target.value))}
                                style={{
                                    marginLeft: "10px",
                                    padding: "5px",
                                    borderRadius: "5px",
                                    border: "1px solid #ccc"
                                }}
                            >
                                <option value="1.0">100%</option>
                                <option value="0.9">90%</option>
                                <option value="0.8">80%</option>
                                <option value="0.3">30%</option>
                                <option value="0.01">1%</option>
                            </select>
                        </div>
                    </div>
                </div>

                {/* –í–∏–¥–µ–æ –ø–∞–Ω–µ–ª—å */}
                <div style={{
                    display: "flex",
                    justifyContent: "center",
                    gap: "30px",
                    flexWrap: "wrap",
                    marginTop: "20px"
                }}>
                    <div style={{ textAlign: "center" }}>
                        <h3>–ú–æ–µ –≤–∏–¥–µ–æ</h3>
                        <video
                            ref={videoRef}
                            autoPlay
                            playsInline
                            muted
                            style={{
                                width: "100%",
                                maxWidth: "400px",
                                height: "300px",
                                border: "3px solid #007bff",
                                borderRadius: "10px",
                                backgroundColor: "#000"
                            }}
                        />
                    </div>

                    <div style={{ textAlign: "center" }}>
                        <h3>–¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è –æ—Ç –¥—Ä—É–≥–∏—Ö</h3>
                        <canvas
                            ref={canvasRef}
                            style={{
                                width: "100%",
                                maxWidth: "400px",
                                height: "300px",
                                border: "3px solid #28a745",
                                borderRadius: "10px",
                                backgroundColor: "#000"
                            }}
                        />
                        {currentSpeaker && (
                            <div style={{ marginTop: "10px", color: "#666" }}>
                                {currentSpeaker.first_name} {currentSpeaker.last_name}
                            </div>
                        )}

                        {isAudioStreaming && (
                            <div style={{ marginTop: "10px" }}>
                                –£—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞:
                                <div style={{
                                    width: "200px",
                                    height: "20px",
                                    backgroundColor: "#ddd",
                                    display: "inline-block",
                                    marginLeft: "10px",
                                    borderRadius: "10px",
                                    overflow: "hidden"
                                }}>
                                    <div style={{
                                        width: `${Math.min(audioLevel * 1000, 100)}%`,
                                        height: "100%",
                                        backgroundColor: audioLevel > 0.01 ? "#4CAF50" : "#f44336",
                                        transition: "width 0.1s"
                                    }} />
                                </div>
                            </div>
                        )}
                    </div>
                </div>

                {activeUsers.length > 0 && (
                    <>
                        <br /><br /><br />
                        <h3>–ü–æ–¥–∫–ª—é—á–µ–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏</h3>
                        {activeUsers.map((username) => (
                            <div key={username}>@{username}</div>
                        ))}
                    </>
                )}
            </div>
        </>
    )
}